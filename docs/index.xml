<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>B-Hood Tech Blog</title>
    <link>https://b-hood.site/</link>
    <description>Recent content on B-Hood Tech Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Sat, 21 Nov 2020 22:19:40 +0900</lastBuildDate><atom:link href="https://b-hood.site/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>VSCode で true と false の色分け</title>
      <link>https://b-hood.site/articles/vscode-boolean-colorize/</link>
      <pubDate>Sat, 21 Nov 2020 22:19:40 +0900</pubDate>
      
      <guid>https://b-hood.site/articles/vscode-boolean-colorize/</guid>
      <description>boolean の mapping を書くと true と false が見づらいため、 VSCode で true を緑、false を 赤 で表示して見やすくします。
settings.json
&amp;#34;editor.tokenColorCustomizations&amp;#34;: { &amp;#34;textMateRules&amp;#34;: [ { &amp;#34;scope&amp;#34;: &amp;#34;constant.language.boolean.false&amp;#34;, &amp;#34;settings&amp;#34;: { &amp;#34;foreground&amp;#34;: &amp;#34;#D3569B&amp;#34; } }, { &amp;#34;scope&amp;#34;: &amp;#34;constant.language.boolean.true&amp;#34;, &amp;#34;settings&amp;#34;: { &amp;#34;foreground&amp;#34;: &amp;#34;#9BD356&amp;#34; } }, ] } </description>
    </item>
    
    <item>
      <title>browserslist-config-google でモダンブラウザ向け最適化をする</title>
      <link>https://b-hood.site/articles/browserslist-config-google/</link>
      <pubDate>Wed, 04 Nov 2020 00:00:00 +0900</pubDate>
      
      <guid>https://b-hood.site/articles/browserslist-config-google/</guid>
      <description>browserslist のデフォルトは、IE 11 も含まれていてさすがにモダンじゃないなーと感じます。 個人的には Babel だけで自動的に IE 対応することは難しいと考えているため、 いっそのこと browserslist からレガシーブラウザを切り捨てます。
$ browserslist &amp;#34;defaults&amp;#34; and_chr 85 and_ff 79 and_qq 10.4 and_uc 12.12 android 81 baidu 7.12 chrome 86 chrome 85 chrome 84 edge 86 edge 85 firefox 82 firefox 81 firefox 80 firefox 78 ie 11 ios_saf 14 ios_saf 13.4-13.7 ios_saf 13.3 ios_saf 12.2-12.4 kaios 2.5 op_mini all op_mob 59 opera 71 opera 70 safari 14 safari 13.1 samsung 12.</description>
    </item>
    
    <item>
      <title>【アーカイブ】How to make grid layout in Editor.js</title>
      <link>https://b-hood.site/articles/editor-js-grid/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://b-hood.site/articles/editor-js-grid/</guid>
      <description>&amp;lt;ins class=&amp;ldquo;adsbygoogle&amp;rdquo; style=&amp;ldquo;display:block&amp;quot;ｌｓ data-ad-client=&amp;ldquo;ca-pub-7008780049786244&amp;rdquo; data-ad-slot=&amp;ldquo;5063315418&amp;rdquo; data-ad-format=&amp;ldquo;auto&amp;rdquo; data-full-width-responsive=&amp;ldquo;true&amp;rdquo;&amp;gt;Use Editor.js more flexibly Editor.js is one of block editors. The article data format is JSON not HTML, so it can manage article data more cleanly and formally.
Editor.js can&amp;rsquo;t nest blocks to keep simplicity. So it is useful for general articles that blogs, news and so on. But difficult for special layout that landing page and so on.
Therefore, I published a grid layout plugin for Editor.</description>
    </item>
    
    <item>
      <title>【アーカイブ】ImageMagickで16:9トリミングを自動化</title>
      <link>https://b-hood.site/articles/trimrate/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://b-hood.site/articles/trimrate/</guid>
      <description>皆さんは画像を SNS や自身のブログなどに投稿する際に加工したことはないでしょうか？ Twitter では画像が自動的に 16:9 で表示されるため、あらかじめ 16:9 でトリミングしておくことでどのように表示されるかを調整できます。 トリミング機能は Android 版にはありますが Web 版にはないため、PC からの画像投稿のときに少し面倒に感じたりします。
画像編集の自動化といえば ImageMagick そこで GIMP などの画像編集ソフトが必要になりますが、私は ImageMagick を利用しています。 画像の加工を自動で行うためのコマンドラインが用意されており、たとえば以下のようにすれば png ファイルを一括で余白トリミングできます。 GIMP でいう「最小枠で切り抜き」機能ですね。
画像サイズを指定しての切り抜きは ImageMagick の crop オプションを使います。 座標 (X, Y) の位置で幅 W px、高さ H px のトリミングをするには以下のコマンドを打ちます。
しかし、残念ながら比率（16:9 など）の指定によるトリミングには対応していません。 そこで、比率指定によるトリミングのコマンドをシェルスクリプトで作りました。
trimrate コマンドを作ってみた 結論から言うと、比率指定によるトリミングコマンドを以下のように作りました。
このシェルスクリプトを trimrate というファイル名で保存します。 保存先は /usr/local/bin などのパスが通っているところが便利です。 そして chmod +x trimrate で実行権限を与えて以下の構文でトリミングを行います。
コマンドの動作的には、比率から切り抜きの幅高さを計算して ImageMagick の crop 機能を呼び出しているだけです。 デフォルトだと画像の上部でトリミングするため、-gravity center オプションを加えて中央でトリミングしています。
for 文で一括処理する trimrate コマンドだけだと mogrify のように複数のファイルを一括処理できません。 しかし、bash の for 文で画像ファイルごとに trimrate を実行して一括処理させることはできます。</description>
    </item>
    
    <item>
      <title>【アーカイブ】webp 画像形式でファイルサイズが 92% 削減された</title>
      <link>https://b-hood.site/articles/webp/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://b-hood.site/articles/webp/</guid>
      <description>皆さんこんにちは 😀 私はいま作っているこのサイトでは、シンプルかつこだわりをもってあれこれやっているつもりです。 そのひとつとして、Google の PageSpeed Insightsというものを利用しています。 これはページの読み込み速度をスコアリングして、さらにスピードを改善するためのアドバイスもしてくれるすばらしいツールです。 ページスピードは Web 検索にも影響すると言われ、サイトを運営している方であれば多くの人が活用できるのではないでしょうか？ この記事では、読み込み速度改善の 1 つとしてWebp 画像形式の導入について紹介したいと思います。
まずはページスピードを測定 まずは自分の Web サイトの状況を確認するために、PageSpeed Insights を使います。 サイトの URL を入力して測定するだけで、数十秒後にはスコアが表示されると思います。 なお、PageSpeed Insights はモバイルと PC に分けて測定、スコアリングするため、両方確認する必要があります。
私のサイトでは、まず重要な箇所としてランディングページ (LP) の測定をしてみました。 LP には特にコンテンツもなく負荷が軽いので、スコア 90 点超えの良い結果となりました。
しかし、記事一覧ページでは 80 点台という標準的な結果でした。
こんなとき、Google はスピード改善のための提案をしてくれます。 そこに「次世代フォーマットでの画像の配信」というものがありました。 これは、Web サイトに埋め込まれている jpg や png などの形式の画像を、 jpeg2000 や Webp という画像形式に置き換えることで通信負荷が抑えられることを意味しています。 さらに、次世代フォーマットを導入することによるファイルサイズの削減量まで教えてくれるといういたわり尽くせリです。
Webp 形式に変換する というわけで、さっそく Web サイト中のあらゆる png, JPEG ファイルを Webp に変換してみました。 Ubuntu をお使いの方は、以下のコマンドで Webp に変換するコマンドをインストールできます。
そして、以下のコマンドで png, JPEG ファイルを一括で Webp ファイルに変換できます。 なお、cwebp コマンドは変換のクオリティがデフォルトで 80% に設定されています。 コマンドオプションを追加して、クオリティを変更することも可能です。</description>
    </item>
    
    <item>
      <title>【アーカイブ】「静的サイトジェネレータ」という言葉だけで静的サイトを作った話</title>
      <link>https://b-hood.site/articles/staticgen/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://b-hood.site/articles/staticgen/</guid>
      <description>皆さんこんにちは。 私はつい最近静的サイトジェネレータという言葉を聞きました。 「静的」に興味を惹かれた私が、静的サイトジェネレータという言葉だけで静的サイトを作ってみた話をまとめます。 今回の記事は私の憶測が多いのでご注意ください（笑）
なお、当サイトはこの記事の通りに Laravel &amp;amp; wget &amp;amp; nginx による静的サイトとなっています。 もしご興味があれば、GitHubを見ていただけると幸いです。
静的サイトとは？ まず、静的サイトの意味から考える必要があります。 おそらくこれは静的なサイト、つまりリクエストに対して Web サーバのレスポンスコンテンツが変わらないということです。 ということは、HTML, CSS, 画像アセットなどの静的なファイルを提供するだけのサイトであれば広義の静的サイトに当てはまります。
静的サイトのメリット・デメリット ただ html を提供するだけの静的サイトであれば、なんだかインターネット初期の &amp;lsquo;90 年代のように感じてしまいます。 そこで、静的サイトのメリットをまとめてみました。
 Web サーバが PHP などを実行することはないため、動的コンテンツによる脆弱性が存在しない。 すでにレスポンスコンテンツが用意されているため、高速である。 レンタルサーバなどでは PHP を実行できない場合も多く、静的サイトであればサーバに求める要件が低い。  次に、静的サイトのデメリットをまとめます。
 端末（スマートフォン、PC など）によってサーバレスポンスを変化させることは難しい。 REST API や検索機能などの提供は不可能。  静的サイトジェネレータとは？ 静的サイトの意味が定まったところで、次は静的サイトジェネレータについて考えます。 これは静的サイトを作る、つまり静的サイトを作る元データがあり、それを加工して静的コンテンツを作るツールと考えられます。 ということは PHP で動的コンテンツを作り、それを php コマンドで html 出力して Web サーバで公開すれば、 PHP は静的サイトジェネレータになるということです。 逆に、アクセスがあった時点で PHP を実行して html を出力するのであれば、PHP は動的サイトのエンジンやエグゼキュータと呼べるのでしょう。
クローラは静的サイトジェネレータ？ 以上のことを踏まえると、どんな動的コンテンツでも、サーバからダウンロードしたときには静的コンテンツになっていることになります。 JavaScript による DOM 操作などは、サーバとしては静的であるとみなします。 よって、ローカルな開発環境で動的サイトのサーバを立ち上げ、それをクローラで html として取得すれば、 クローラは静的サイトジェネレータということになります。</description>
    </item>
    
    <item>
      <title>【アーカイブ】【CI】git commit 時に自動整形 &amp; コーディングチェックする</title>
      <link>https://b-hood.site/articles/pre_commit/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://b-hood.site/articles/pre_commit/</guid>
      <description>皆さんこんにちは。 プログラミングやコーディングを続けていくうちに、過去に自分が書いたコードの意味が分からなくなったりしたことはないでしょうか？ 今回は、中〜大規模な開発をする際に重要な**サーバレスな継続的インテグレーション（CI）**について書きたいと思います。
導入方法はこちら
継続的インテグレーション（CI）とは WikiPedia継続的インテグレーション（CI）とは、ソフトウェア開発においてソースコードの品質や保守性を保ち、持続可能な開発を続けていくための方法です。 つまり、ほかの人が見ても理解しやすく、また自分が書いた古いコードでも処理内容が理解できるようにプログラミングしていくということですね。
個人の趣味のスクリプトであれば CI を導入する必要はないかもしれません。 しかし、お仕事などでのチームでの開発では重要になると思います。 また GitHub で公開するものに対しても、CI を導入するとメリットが大きいと思います。
ソースコードの属人性（その人にしか分からないような書き方）を解消するために、開発ルールを定めることがあります。 たとえば、コーディングスタイルを定義したり（Google C++ Style Guide など）、コードレビューをするなどです。 これらは整形ツールやコーディングチェック（lint）を使って自動化できます。
サーバレスで CI を導入 CI を導入する方法として、CI サーバを立てる方法があります。 たとえば、GitHub では Travis CI を導入することで、git commit 時に自動で CI を実行してくれます。 さらに、CI の実行結果を GitHub のバッジ として公言でき、リポジトリの質を保証する 1 つの指標にできます。
しかし、CI サービスは有料プランのものもあり（Public リポジトリは無料も）、特に社内開発ではコストになる場合があります。 そこで、CI をローカル環境に導入し、git commit 時に自動でコーディングチェックと自動整形をしたいと思います。
pre_commit フックを使う Git には、コミット時などにスクリプトを実行するフック機能があります。 その 1 つに pre_commit というものがあり、これはコミットをする直前に発動します。 よって、pre_commit に CI のプログラムを記述することで、git commit したときにコーディングチェックや自動整形を実行できます。
自動化ツール コーディングチェックや自動整形を行うコマンドラインツールです。
 clang-format　C/C++ の自動整形をします。 cpplint　C/C++ の静的コード解析をします。 Prettier　HTML, CSS, JavaScript, PHP, Markdown, Yaml などの自動整形をします。 ESLint　JavaScript の静的コード解析をします。 phpmd　PHP の静的コード解析をします。  pre_commit 例 私が開発するときに導入している Git フックは、このリポジトリで公開しています。 blue-hood/.</description>
    </item>
    
    <item>
      <title>【アーカイブ】【Git×Twitter】連携 &amp;amp; 通知してコミットの質を上げよう</title>
      <link>https://b-hood.site/articles/gitwitter/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://b-hood.site/articles/gitwitter/</guid>
      <description>いつも私は Git のコミットメッセージを適当に済ませてしまうのですが、git push するとツイートされるしくみを導入したらコミットメッセージの質が格段に上がりました。
導入前
導入後
（英語から日本語に変わっているのはさておき、）コミットメッセージの内容が具体的になりました。また、Twitter を意識してかちょっと感情的なところもちらほらありますね。このような Git と Twitter の連携をサーバレスで導入する方法を紹介します。
インストール方法
2019/03/30 gitwitter のレアケース対策をしました。
Webhook は意外と不便 Git と Twitter の連携でメジャーと思われるのは、Webhook を利用する方法です。GitHub や Bitbucket には、リポジトリへの push イベントごとに POST リクエストを投げてくれる機能があります。それを別途 Web サーバで拾ってツイートします。いわゆるクラウドハブはこの機能を利用しているわけですね。
しかし、クラウドハブを利用するには月額料金がかかったり、無料だとしても月ごとの使用回数に制限があったりします。また自前で Webhook を拾うには、サーバが必要なのはもちろん HTTPS 通信をするためのドメインと証明書なども必要になります。Git の push をツイートするためだけに Webhook を利用するのは、ちょっとオーバーな気がします。
また、実際に私が Webhook を導入してみて思ったのは、ツイートするかを毎回制御できないため不便だということです。たとえば、タイポを修正するだけのささいな push に対してもツイートされてしまい、手動で無駄なツイートを消すということがありました。タイムラインを荒らしてしまったと思いますね。
サーバレスで連携する そこで、Webhook を使わずクライアントで動かす連携アプリケーションを作ることにしました。これならサーバレスだしツイートするかも毎回決めることができます。ツイートする文章はシェルスクリプトで git log を呼び出したりして組み立てました。ツイートするには TwitterOAuth を使って Twitter REST API をたたく PHP スクリプトを書きました。使い方はこんな感じです。
tweet コマンド GitHub: Hata6502/tweet
コマンドラインからツイートします。標準入力から読み込む汎用的な作りにしたので、Git との連携以外にも応用できるかもしれません。
(1) /usr/local/src などにダウンロードします。</description>
    </item>
    
    <item>
      <title>【アーカイブ】【jQuery不要】JS で章番号 &amp; リンク付きの目次を自動生成する</title>
      <link>https://b-hood.site/articles/table-of-contents/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://b-hood.site/articles/table-of-contents/</guid>
      <description>WordPress 製のサイトなどで見かける目次。 そのページの内容がリストとして一目で確認できるため、Web サイトにも大きな役割を果たします。 JavaScript で目次を自動生成する方法を紹介します。
JavaScript で目次を作る 基本的に見出しは h1〜h6 でタグ付けされているかと思います。 これらのタグには見出しという情報だけでなく、見出しどうしの階層関係も表現されています。 よって、h1〜h6 タグは目次を作るのに最適な情報源と言えます。
目次を置く場所に &amp;lt;ol class=&amp;quot;table-of-contents&amp;quot;&amp;gt;&amp;lt;/ol&amp;gt; を配置して、この要素の中に JavaScript で目次の情報を書き込んでいきます。
上記が目次を自動生成する JavaScript の完成形になります。
QuerySelectorAll で h1〜h6 タグを探す まずは .table-of-contents を設置した親要素から、h1〜h6 要素を探し出します。
h1〜h6 タグを元に目次要素を生成 探し出した h1〜h6 タグが変数 heading に入ってループ処理されているとします。 まずは目次 1 行分に相当する li 要素を生成し、その中に a 要素と ol 要素を入れています。 a 要素には h1〜h6 のテキストを入れて、さらにアンカーリンクとして href 属性に #section-${table_of_contents_counter++} を入れています。 変数 table_of_contents_counter は 1、2、3…と増分していくので、生成されるアンカーリンクも #section-1、#section-2、…となります。 ol 要素は、見出しの階層構造を作るために後で必要となります。
h1〜h6 タグにアンカーリンクも紐付け 生成したアンカーリンクを h1〜h6 タグの id に設定します。 これによって、目次の要素をクリックしたときにページ内ジャンプさせます。 さらに、必要であれば anchor-link クラスを付けて CSS でデザイン調整しましょう。</description>
    </item>
    
    <item>
      <title>【アーカイブ】【PHPMD 対応】husky &amp;amp; lint-staged で CI を実行する</title>
      <link>https://b-hood.site/articles/husky/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://b-hood.site/articles/husky/</guid>
      <description>みなさんこんにちは、今回は husky と lint-staged を使って CI 環境をローカルに構築する方法を紹介したいと思います。
継続的インテグレーション（CI）とは WikiPedia継続的インテグレーション（CI）とは、ソフトウェア開発においてソースコードの品質や保守性を保ち、持続可能な開発を続けていくための方法です。 つまり、ほかの人が見ても理解しやすく、また自分が書いた古いコードでも処理内容が理解できるようにプログラミングしていくということですね。
個人の趣味のスクリプトであれば CI を導入する必要はないかもしれませんが、お仕事などでのチームでの開発では重要になると思います。 また GitHub で公開するものに対しても、CI を導入するとメリットが大きいと思います。
ソースコードの属人性（その人にしか分からないような書き方）を解消するために、開発ルールを定めることがあります。 たとえば、コーディングスタイルを定義したり（Google C++ Style Guide など）、コードレビューをするなどです。 これらは整形ツールやコーディングチェック（lint）を使って自動化できます。
サーバレスで CI を導入 CI を導入する方法として、CI サーバを立てる方法があります。 たとえば、GitHub では Travis CI を導入することで、git commit 時に自動で CI を実行してくれます。 さらに、CI の実行結果を GitHub のバッジ として公言でき、リポジトリの質を保証する 1 つの指標にできます。
しかし、CI サービスは有料プランのものもあり（Public リポジトリは無料も）、特に社内開発ではコストになる場合があります。 そこで、CI をローカル環境に導入し、git commit 時に自動でコーディングチェックと自動整形をしたいと思います。
huskey と lint-staged を使うメリット コミット時に CI スクリプトを実行するには pre-commit を自前で記述することも可能です。 しかし、ほかの人と共同開発する場合では手動で pre-commit および自動整形ツール（prettier や eslint）を導入する必要がありました。
そこで、husky を使って pre-commit をフックし、lint-staged でコーディングチェックと自動整形を実行させたいと思います。 リポジトリ直下に npm で husky、lint-staged、prettier、eslint などをインストールすれば、以降は npm install だけで CI 環境が整います。</description>
    </item>
    
    <item>
      <title>【アーカイブ】ふせんプログラミング</title>
      <link>https://b-hood.site/articles/postit-program/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://b-hood.site/articles/postit-program/</guid>
      <description>物の整理をしていたらおもしろい資料が出てきたので公開します。
&amp;lt;ins class=&amp;ldquo;adsbygoogle&amp;rdquo; style=&amp;ldquo;display:block&amp;quot;ｌｓ data-ad-client=&amp;ldquo;ca-pub-7008780049786244&amp;rdquo; data-ad-slot=&amp;ldquo;5063315418&amp;rdquo; data-ad-format=&amp;ldquo;auto&amp;rdquo; data-full-width-responsive=&amp;ldquo;true&amp;rdquo;&amp;gt;ふせんプログラミングによるバイナリエディタのプログラム。 確か Z80 か 8080 だったような。</description>
    </item>
    
    <item>
      <title>【アーカイブ】シェルで lastmod changefreq 付きの sitemap.xml を作る</title>
      <link>https://b-hood.site/articles/sitemap/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://b-hood.site/articles/sitemap/</guid>
      <description>こんにちは、今回は内容の濃い記事が書けそうでワクワクしています😀　このサイトでは、PHP を使わず静的な html でコンテンツを配信しています。 せっかく作っている Web サイト、この存在をクローラに気づかせるためには sitemap.xml の設置が重要となります。 今回は、sitemap.xml を自動的かつ**こだわりをもって(?)**生成する方法を紹介します。
このサイトの sitemap.xml2019/05/04 sitemap.xml を生成するコマンドを作りました！GitHub
sitemap.xml の構造 sitemap.xml は、そのサイトのサイトマップを表す xml ファイルです。 一般的にドキュメントルートに設置して、robots.txt で sitemap.xml の場所を指定します。
robots.txt の例
sitemap.xml はさらに別の xml ファイルに分割することもできるのですが、 1 ファイルにすべてのページの情報を書き込むとするとこのような形式になります。
url タグで 1 ページ分の情報として列記していきます。 url タグ内の情報を以下のようにまとめました。
 loc: ページの URL(必須） lastmod: ページの最終更新日時（任意） changefreq: ページの更新頻度（任意、hourly, daily, weekly, monthly, yearly など） (priority): そのページの重要度（任意、今回は省略）  最低限の sitemap.xml を作るのであれば、loc だけを書いて簡易的に済ませることもできます。 しかし、できれば lastmod と changefreq も書いてサイトの情報を詳しく伝えたいところです。 ちなみに priority はページの重要度を 0.0〜1.0 の範囲内で指定できるのですが、Google はこの値を無視しているそうです。 まあ、私としても priority は主観的であいまいなデータですし、あまりあてにならないかなと思います。 もちろん全部のページを priority=1.</description>
    </item>
    
    <item>
      <title>【アーカイブ】マイコンを使わないアナログ式電子オルゴールを作った</title>
      <link>https://b-hood.site/articles/analog-orgel/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://b-hood.site/articles/analog-orgel/</guid>
      <description>皆さんこんにちは。 今回は、私が 1 年がかりで作った「アナログ式電子オルゴール」の紹介をしたいと思います。
動作風景 ※音量小さいです。
元ネタはピアノロール 私が中学生のころ、クラシックなミッキーマウスのアニメーションを見るのが好きだったのですが、そこにピアノロール が出ていました。これは、ピアノの演奏情報を時系列的に記録した紙媒体であり、穴が空いているところに対応する鍵盤が自動的に押されるしくみのようです。
これをもとに、幅 40 mm の紙テープで演奏データを記録することにしました。 本家のピアノロールは、鍵盤 1 つずつに 1 ライン使うため非常に幅の広い紙テープが必要になります。 そこで、音階（ドレミファソラシドと#）を 4 ビット、オクターブを 3 ビット、ノートオン／オフを 1 ビットの合計 8 ビットで表現しています。
回路図 画像形式と .CE3 形式で配布します。 .CE3 を BSch3V で開けば高解像で確認できるためお勧めします。 なお、パスコンなどのノイズ対策や電源の振動対策を行っておらず、自己責任にてお願いします。
電源 15V の AC アダプタからレールスプリッタで ±7.5V 電源を生成、プッシュプルで大電流対応。 そのほか、NJM4580DD オペアンプの動作電圧を作ったり、デジタル用+5V を三端子レギュレータで作っています。
 CE3 ファイル  紙テープ巻取回路 紙テープを一定の速度で巻き取ります。 モータの速度をフィードバックで制御していますが、なんと速度センサもまたモータ。 紙テープにローラーを当ててモータの軸を回し、微弱な起電圧を 300 倍に増幅します。 そして、半固定抵抗によって定めた基準電圧とコンパレータによって比較し、 紙テープを巻き取るモータをオン／オフします。 モータは激しいノイズ源になりそうですので、3V 電池を使って電源を隔離しています。
 CE3 ファイル  紙テープ読取回路 黒を 1、白を 0 のデジタル信号として、8 ビット幅の紙テープをフォトリフレクタで読み取ります。 1 ビットはノートオン信号として、これが Hi のときに残りの 7 ビットを読み取るようにします。</description>
    </item>
    
    <item>
      <title>【アーカイブ】リーダブルコードが強迫観念になりつつあること</title>
      <link>https://b-hood.site/articles/readable-code/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://b-hood.site/articles/readable-code/</guid>
      <description>みなさんこんにちは 😁 今回は「リーダブルコード」に対する懐疑的な意見を述べたいと思います。
10 年前の自分をコードレビュー まずは、私が 10 年前、中学生のころに作ったブロック崩しのプログラムを紹介したいと思います。 言語は HSP (Hot Soup Processor) というものでして、とても初心者向けの言語です。 BASIC に似た言語ともいえます。
プログラムのファイル名は 本当のブロック崩し.hsp（笑） 当時ブロック崩しを作るのに一度挫折したため、ブロック崩し.hsp には違うプログラムが入っていました。 そして 2 回目でブロック崩しのプログラミングに成功したので、本当のブロック崩し.hsp と名付けたのです（笑笑）
そのプログラムがこちらです。コードレビューしていきたいと思います。
😂🤣😅🙄😥
レビューしてたらきりが無さそうですが、ツッコミどころを頑張って 3 つに絞り込んでみました。
ローマ字を使っている ところどころにローマ字があります。 たとえば、「shoki」は初期化処理のことです。 「oto1.wav」は効果音 1 の音声ファイルですね。 「atari」は、ボールとブロックが当たったときの処理のことです、まるでゲーム会社を彷彿させるネーミングです。
もちろん、こんなネーミングはダメです。 ちゃんと英語を使いましょう、「brock.bmp」のように。 これはブロックの画像ファイルです、brock、block?…… まあ、中学生だし英語のスペルミスは許してね。
変数名は 1 文字 プログラムを難読化させている大きな原因の 1 つですね。 変数名は m=0, c=0, w=1 のように 1 文字です。
変数 x, y がボールの座標だと思うでしょう？ 実は、変数 a, b がボールの座標です。 それでは x=150 と初期化している変数 x は何に使用しているかというと……未使用です。 つまり、初期化しているのに一切使用していません（笑）
そのほか、スコアを記憶する変数が c（s ではない）など、初期の BASIC っぽいですね。 確か BASIC は変数名 2 文字までという制約がありませんでしたっけ？</description>
    </item>
    
    <item>
      <title>【アーカイブ】大規模な作業のときは「付箋スタック」を積む</title>
      <link>https://b-hood.site/articles/sticky-stack/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://b-hood.site/articles/sticky-stack/</guid>
      <description>皆さんこんにちは。 今回は番外的な記事として、私個人で編み出した仕事術ふせんスタックについて紹介したいと思います（笑） おもしろ半分で読んでいただけると幸いです。
人間には把握の限界がある まず最初に、人間には把握の限界があることを前提とします。 というのは、人間のワーキングメモリはコンピュータのように数 GB あるわけではなく、たいてい数単語分しかないということです。 参考文献 によると、人間のワーキングメモリは 7±2 チャンクの範囲だと言われています。 仕事などで大規模な作業を行うのに対して、短期記憶の使用は避けるべきだと言えます。
作業の影響は連鎖していく 当然のことではありますが、作業を行うとその影響を対応するために新しい作業が生まれていくことがあります。 たとえば、新しい元号へ対応するためにAというシステムを改修した場合、Aを利用しているシステムB、C、Dも改修が必要になり、さらに……という連鎖が発生します。 このとき、見通しが浅く「平成の 2 文字を令和に置き換えるだけ」程度に考えてしまうと、その作業量の大きさに気付くことができません。
作業漏れを起こさないコンピュータの構造 これも当然ですが、コンピュータは指示された命令通りに漏れを起こすことなく作業を遂行しますね。 コンピュータが処理を漏れなく行う記憶構造として、**スタック**があります。 これはコンピュータが現在何の処理をしているか、この処理が終わったら次は何をするか、といったプログラムの実行ステータスを記憶するためにも使われています。 これに似たような方法を取り入れれば、機械的ながらも作業漏れを減らすことができるのではないでしょうか？
ふせんスタック それではふせんスタックの方法を例をまじえながら紹介します。 まず、作業ステータスを記録するためにふせんを使います。 ふせんに今回のタスク例として「平成 → 令和移行」と書きます。 そして、これから行うタスク「平成 → 令和移行」に「←」マークを付けます。
次に、「平成 → 令和移行」のタスクを完了するにはどんな作業が必要かを書き出します。 ここでは、「文字列置換」と「画像に埋め込まれた文字の置換」をする必要があるため、 この 2 つをふせんに書き出して**「平成 → 令和移行」の隣**に貼ります。 このようにして作業の階層構造を表現します。 また、「文字列置換」のタスクに「←」マークを付けます。
「文字列置換」のタスクを完了するには、app/ ディレクトリ配下のファイルと resource/ ディレクトリ配下のファイルを編集する必要があります。 この 2 つのディレクトリをふせんに書き出して「文字列置換」のタスクの隣に貼ります。 そして、resource/ 配下から着手するため「resource/ 配下」のタスクに「←」を書きます。 さらに、「平成 → 令和移行」のタスクを完了するには、西暦と和暦を変換するプログラムを改修する必要が出てきました。 そこで「西暦 → 令和変換実装」のふせんを追加します。
resource/ 配下の文字列置換が完了したため、「resource/ 配下」のふせんを破棄します。 そして、次のタスク「app/ 配下」に「←」を付けます。
app/ 配下の作業も終わったため、「app/ 配下」のふせんを破棄します。 これによって文字列置換のタスクもすべて完了したため、「文字列置換」のふせんも破棄します。 次に行うタスクを選び、ここでは「西暦 → 令和変換実装」を行うことにするため「←」マークを付けます。</description>
    </item>
    
    <item>
      <title>【アーカイブ】記事を Git で管理することにした</title>
      <link>https://b-hood.site/articles/git-article/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://b-hood.site/articles/git-article/</guid>
      <description>このサイトでは記事をデータベースに保存していたのですが、Git での管理に移行しました。 ここでは Markdown と Laravel で記事を Git 管理する方法をまとめます。
Git と記事は相性が良い WordPress などの CMS には、下書き保存や承認フロー機能など、複数人で運営するための機能が実装されています。 また更新履歴を残せるため、誰がどこを書き換えたのか調査でき、以前のバージョンに戻すことも容易となっています。 このサイトはオリジナルのシステムで記事を管理していますが、このような機能を自力で実装するのはおおがかりです。
そこで、記事の管理をデータベースからファイルシステムに移行し、記事ディレクトリを Git で管理することにしました。 記事の管理機能と Git は共通点が多くあります。 たとえば、CMS の機能は以下のように代替可能です。
 更新履歴 → コミットログ 下書き保存 → ブランチを切って作業 承認フロー →（GitHub の）Pull Request  さらに、次のようなメリットもあります。
 記事をテキストエディタで編集するため、CMS に編集機能を実装する必要がない。 記事データをファイルとして配置するため、textlint や Prettier などのツールを適用しやすい。  というわけで、CMS での実装を減らしつつ記事管理を高機能にできます。
デメリットとしては、
 Git を非エンジニアに使わせるのは学習コストが高いかも。 ファイルから記事データを読み込むため、読み込み負荷が非常に大きい。  が挙げられます。 視覚的に Git を操作できるツールを導入したりして、Git 独特の操作の難しさを解消する必要がありそうですね。 読み込み負荷の問題については後述します。
FrontMatter でメタデータを管理する 私は記事を Markdown で書いているのですが、記事のタイトルなどのメタデータはデータベースのカラムとして管理していました。 そこで、これらのメタデータも FrontMatter として記事本文の .md ファイルに埋め込みます。Markdown の先頭行に --- で囲んだ YAML データを定義できます。</description>
    </item>
    
    <item>
      <title>【アーカイブ】面倒なファイル名は付けずに8文字IDで管理しよう</title>
      <link>https://b-hood.site/articles/mvhash/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://b-hood.site/articles/mvhash/</guid>
      <description>みなさんはこんな感じのファイル管理を見たことはないでしょうか？
 レイアウト_トップ画面.xlsx レイアウト_登録画面.xlsx レイアウト_トップ画面_20190101 提出版.xlsx レイアウト_登録画面_20190101 提出版.xlsx  バージョン管理システムが導入されていないオフィスにいたとき、作業用 PC の作業ディレクトリ内がこんな感じでした（笑）。 ちなみにいまはバージョン管理システムが導入されており、少し作業効率が改善されたのを覚えています。 とはいっても、バージョン管理システムもその人の使い方次第で ↑ のような状況になってしまうのですが……
Web サイトやプレゼンテーション資料を作るときなど、画像素材をいろんなところから収集してくるときがあります。 すると、ファイル名は「猫の画像 1.jpg」「ScreenShot20190101-1.png」「12de944eff….jpg」など、ファイル名の規則性がバラバラで意味を成さなくなります。 そんなときに、ファイル名を8 文字 IDに一括で置き換えて統一する方法を紹介します。
mvhash コマンドを作ってみた Linux や Mac をお使いであれば、以下のシェルスクリプトを導入することで 8 文字 ID へ変換できます。
上記シェルスクリプトを mvhash というファイル名で /usr/localbin などのパスが通っているところに配置します。 そして、以下のようにすれば 8 文字 ID に変換されます。
せっかくですので、mvhash コマンドの解説をしていきたいと思います！💪
コマンド引数で while ループ $ mvhash *.jpg *.png のようにワイルドカードを使ったコマンドを実行するとき、bash がワイルドカードの展開をします。 よって、$ mvhash 猫の画像1.jpg ScreenShot20190101-1.png 82f23189….jpg というコマンドを入力したとみなされます。 mvhash シェルスクリプトでは、与えられたコマンドライン引数ごとにループ処理をさせます。 while 文のループ条件は「引数が 0 でないとき」とし、shift コマンドによって引数のシフトというものをします。 これによって第一引数 $1 が削除され、そのあとに続く引数が $1、$2、…となります。</description>
    </item>
    
  </channel>
</rss>
